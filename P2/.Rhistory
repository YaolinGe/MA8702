V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
epsilon = norm(abs(theta_new - theta), type = "2") / norm(theta, type = "2")
theta = theta_new
No_iter = No_iter + 1
}
# Output:
# C = F*Sigma*F.T + T
C_matrix <- function(theta){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
Sigma = Matern_cov(sigma, phi, t)
C = Fmatrix %*% Sigma %*% t(Fmatrix) + diag(M) * tau^2
return(C)
}
# Output:
# dC_dtheta = list(dC_dsigma, dC_dphi, dC_dtau)
dCdtheta <- function(theta){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
dC_dsigma = 2*sigma*(1+phi*H)*exp(-phi*H)
dC_dphi = -sigma**2 * phi * H^2 * exp(-phi*H)
dC_dtau = 2*tau*diag(N)
dC_dtheta = list(dC_dsigma=dC_dsigma, dC_dphi=dC_dphi, dC_dtau=dC_dtau)
return(dC_dtheta)
}
# Output:
# dl/dtheta gradient (vector 1xlength(theta))
dldtheta <- function(theta, C, Q, Z){
# Often used variables
dl_dtheta = rep(0,length(theta))
sigma = theta[1]
phi = theta[2]
tau = theta[3]
dC_dtheta = dCdtheta(theta)
dC_dsigma = dC_dtheta$dC_dsigma
dC_dphi   = dC_dtheta$dC_dphi
dC_dtau   = dC_dtheta$dC_dtau
# first component wrt sigma=theta[1]
dl_dtheta[1] = -1/2*tr(Q%*%dC_dsigma) + 1/2*t(Z)%*%Q%*%dC_dsigma%*%Q%*%Z
# second component wrt phi
dl_dtheta[2] = -1/2*tr(Q%*%dC_dphi) + 1/2*t(Z)%*%Q%*%dC_dphi%*%Q%*%Z
# third component wrt tau
dl_dtheta[3] = -1/2*tr(Q%*%dC_dtau) + 1/2*t(Z)%*%Q%*%dC_dtau%*%Q%*%Z
return(dl_dtheta)
}
# Output:
# Hessian (matrix: length(theta) x length(theta))
ddldthetadtheta <- function(theta, C, Q){
# basic derivatives
dC_dtheta = dCdtheta(theta)
# constructing Hessian
ddl_dthetadtheta = matrix(0, ncol=length(theta), nrow=length(theta))
for (i in 1:length(theta)){
for (j in 1:length(theta)){
ddl_dthetadtheta[i,j] = -0.5*tr(Q%*%dC_dtheta[[i]]%*%Q%*%dC_dtheta[[j]])
}
}
return(ddl_dthetadtheta)
}
# Use fisher scoring to find MLE parameters
beta = rbind(-1.1, 1.1, 1.4)
theta = rbind(1.1, 8.5, .03)
MAX_ITER = 100
No_iter = 0
epsilon = 10
Beta = matrix(0, nrow = MAX_ITER, ncol = 3)
Likelihood = matrix(0, nrow = MAX_ITER, ncol = 1)
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
Beta[No_iter, ] = t(beta)
z = y_sampled - G %*% beta
lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
if (is.nan(lik) || is.na(lik) || is.infinite(lik)){
lik = 0
}
Likelihood[No_iter, ] = lik
# Find dC*/dtheta
dC_dSgm = dC_dsigma(theta)
dC_dPhi = dC_dphi(theta)
dC_dTau = dC_dtau(theta)
u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm))) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z))
u_eta = -1 / 2 * sum(diag(solve(C, dC_dPhi))) + 1 / 2 * t(z) %*% solve(C, dC_dPhi %*% solve(C, z))
u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau))) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z))
u = rbind(u_sigma, u_eta, u_tau)
V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
epsilon = norm(abs(theta_new - theta), type = "2") / norm(theta, type = "2")
theta = theta_new
No_iter = No_iter + 1
}
# parameter estimation loop
# (nomenclature as in lecture)
iter = 0
stats = list(c(iter, theta, alpha, l))
while(abs(l-l_old)>tol){
# current residual
Z = y - alpha*mu
# current covariance for the model
C = MaternCov(theta) + theta[3]**2*diag(N)
# current precision for the model
Q = solve(C)
# current gradient
dl_dtheta = dldtheta(theta, C, Q, Z)
# current Hessian
ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# update theta
theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# update alpha
alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# objective value (log-likelihood)
l_old = l
l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
# statistics
iter = iter + 1
stats[[iter]] = c(iter, theta, alpha, l)
}
# loads
library(psych)
# initial guesses
sigma = 1.5
phi = 7.5
tau = 0.1
theta = c(sigma, phi, tau)
alpha = 0.5
# optimization parameters
tol = 1e-5          # value for absolute termination criterion
l = Inf             # likelihood value
l_old = 0           # likelihood value of previous iteration
# Output:
# dC_dtheta = list(dC_dsigma, dC_dphi, dC_dtau)
dCdtheta <- function(theta){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
dC_dsigma = 2*sigma*(1+phi*H)*exp(-phi*H)
dC_dphi = -sigma**2 * phi * H^2 * exp(-phi*H)
dC_dtau = 2*tau*diag(N)
dC_dtheta = list(dC_dsigma=dC_dsigma, dC_dphi=dC_dphi, dC_dtau=dC_dtau)
return(dC_dtheta)
}
# Output:
# dl/dtheta gradient (vector 1xlength(theta))
dldtheta <- function(theta, C, Q, Z){
# Often used variables
dl_dtheta = rep(0,length(theta))
sigma = theta[1]
phi = theta[2]
tau = theta[3]
dC_dtheta = dCdtheta(theta)
dC_dsigma = dC_dtheta$dC_dsigma
dC_dphi   = dC_dtheta$dC_dphi
dC_dtau   = dC_dtheta$dC_dtau
# first component wrt sigma=theta[1]
dl_dtheta[1] = -1/2*tr(Q%*%dC_dsigma) + 1/2*t(Z)%*%Q%*%dC_dsigma%*%Q%*%Z
# second component wrt phi
dl_dtheta[2] = -1/2*tr(Q%*%dC_dphi) + 1/2*t(Z)%*%Q%*%dC_dphi%*%Q%*%Z
# third component wrt tau
dl_dtheta[3] = -1/2*tr(Q%*%dC_dtau) + 1/2*t(Z)%*%Q%*%dC_dtau%*%Q%*%Z
return(dl_dtheta)
}
# Output:
# Hessian (matrix: length(theta) x length(theta))
ddldthetadtheta <- function(theta, C, Q){
# basic derivatives
dC_dtheta = dCdtheta(theta)
# constructing Hessian
ddl_dthetadtheta = matrix(0, ncol=length(theta), nrow=length(theta))
for (i in 1:length(theta)){
for (j in 1:length(theta)){
ddl_dthetadtheta[i,j] = -0.5*tr(Q%*%dC_dtheta[[i]]%*%Q%*%dC_dtheta[[j]])
}
}
return(ddl_dthetadtheta)
}
# parameter estimation loop
# (nomenclature as in lecture)
iter = 0
stats = list(c(iter, theta, alpha, l))
while(abs(l-l_old)>tol){
# current residual
Z = y - alpha*mu
# current covariance for the model
C = MaternCov(theta) + theta[3]**2*diag(N)
# current precision for the model
Q = solve(C)
# current gradient
dl_dtheta = dldtheta(theta, C, Q, Z)
# current Hessian
ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# update theta
theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# update alpha
alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# objective value (log-likelihood)
l_old = l
l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
# statistics
iter = iter + 1
stats[[iter]] = c(iter, theta, alpha, l)
}
# loads
library(psych)
# initial guesses
sigma = 1.5
phi = 7.5
tau = 0.1
theta = c(sigma, phi, tau)
alpha = 0.5
# optimization parameters
tol = 1e-5          # value for absolute termination criterion
l = Inf             # likelihood value
l_old = 0           # likelihood value of previous iteration
# theta = c(sigma, phi, tau)
theta = matrix(c(sigma, phi, tau), ncol = 1)
alpha = 0.5
# optimization parameters
tol = 1e-5          # value for absolute termination criterion
l = Inf             # likelihood value
l_old = 0           # likelihood value of previous iteration
# Output:
# dC_dtheta = list(dC_dsigma, dC_dphi, dC_dtau)
dCdtheta <- function(theta){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
dC_dsigma = 2*sigma*(1+phi*H)*exp(-phi*H)
dC_dphi = -sigma**2 * phi * H^2 * exp(-phi*H)
dC_dtau = 2*tau*diag(N)
dC_dtheta = list(dC_dsigma=dC_dsigma, dC_dphi=dC_dphi, dC_dtau=dC_dtau)
return(dC_dtheta)
}
# Output:
# dl/dtheta gradient (vector 1xlength(theta))
dldtheta <- function(theta, C, Q, Z){
# Often used variables
dl_dtheta = rep(0,length(theta))
sigma = theta[1]
phi = theta[2]
tau = theta[3]
dC_dtheta = dCdtheta(theta)
dC_dsigma = dC_dtheta$dC_dsigma
dC_dphi   = dC_dtheta$dC_dphi
dC_dtau   = dC_dtheta$dC_dtau
# first component wrt sigma=theta[1]
dl_dtheta[1] = -1/2*tr(Q%*%dC_dsigma) + 1/2*t(Z)%*%Q%*%dC_dsigma%*%Q%*%Z
# second component wrt phi
dl_dtheta[2] = -1/2*tr(Q%*%dC_dphi) + 1/2*t(Z)%*%Q%*%dC_dphi%*%Q%*%Z
# third component wrt tau
dl_dtheta[3] = -1/2*tr(Q%*%dC_dtau) + 1/2*t(Z)%*%Q%*%dC_dtau%*%Q%*%Z
return(dl_dtheta)
}
# Output:
# Hessian (matrix: length(theta) x length(theta))
ddldthetadtheta <- function(theta, C, Q){
# basic derivatives
dC_dtheta = dCdtheta(theta)
# constructing Hessian
ddl_dthetadtheta = matrix(0, ncol=length(theta), nrow=length(theta))
for (i in 1:length(theta)){
for (j in 1:length(theta)){
ddl_dthetadtheta[i,j] = -0.5*tr(Q%*%dC_dtheta[[i]]%*%Q%*%dC_dtheta[[j]])
}
}
return(ddl_dthetadtheta)
}
# parameter estimation loop
# (nomenclature as in lecture)
iter = 0
stats = list(c(iter, theta, alpha, l))
while(abs(l-l_old)>tol){
# current residual
Z = y - alpha*mu
# current covariance for the model
C = MaternCov(theta) + theta[3]**2*diag(N)
# current precision for the model
Q = solve(C)
# current gradient
dl_dtheta = dldtheta(theta, C, Q, Z)
# current Hessian
ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# update theta
theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# update alpha
alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# objective value (log-likelihood)
l_old = l
l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
# statistics
iter = iter + 1
stats[[iter]] = c(iter, theta, alpha, l)
}
theta[3]
theta[1]
theta[2]
iter]][2]
print(paste("The parameter estimation coverges after ", iter, "iterations"))
print(paste("The estimate for sigma (true value  1.0) is ", round(stats[[iter]][2], digits=4)))
print(paste("The estimate for phi   (true value 10.0) is ", round(stats[[iter]][3], digits=4)))
print(paste("The estimate for tau   (true value 0.01) is ", round(stats[[iter]][4], digits=4)))
print(paste("The estimate for alpha (true value  1.0) is ", round(stats[[iter]][5], digits=4)))
# parameter estimation loop
# (nomenclature as in lecture)
iter = 0
stats = list(c(iter, theta, alpha, l))
while(abs(l-l_old)>tol){
# current residual
Z = y - alpha*mu
# current covariance for the model
C = MaternCov(theta) + theta[3]**2*diag(N)
# current precision for the model
Q = solve(C)
# current gradient
dl_dtheta = dldtheta(theta, C, Q, Z)
# current Hessian
ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# update theta
theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# update alpha
alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# objective value (log-likelihood)
l_old = l
l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
# statistics
iter = iter + 1
stats[[iter]] = c(iter, theta, alpha, l)
}
print(paste("The parameter estimation coverges after ", iter, "iterations"))
setwd("~/OneDrive - NTNU/NTNU/2021/MA8702/Project/P2")
ls()
dir()
![F matrix decomposition](/F.pdf)
![F matrix decomposition](/F.pdf)
knitr::include_graphics("F.pdf")
We will now use the estimated model parameters to perform kriging prediction. Predict variables $x(s)$, where predictions sites lie on a regular grid of size 25x25 for the unit square. Visualize the Kriging surface and the prediction standard error. Compare with the true field. The expression for the kriging can be shown as below:
\begin{equation}
\boldsymbol{\mu}_{\boldsymbol{x}|\boldsymbol{y}} &= \boldsymbol{\mu} + \boldsymbol{\Sigma F}^T(\boldsymbol{F\Sigma F}^T + \boldsymbol{T})^{-1}(\boldsymbol{y} - \boldsymbol{F\mu}) \\
\boldsymbol{\Sigma}_{\boldsymbol{x}|\boldsymbol{y}} &= \boldsymbol{\Sigma} - \boldsymbol{\Sigma F}^T (\boldsymbol{F\Sigma F}^T + \boldsymbol{T})^{-1}\boldsymbol{F\Sigma}
\end{equation}
We will now use the estimated model parameters to perform kriging prediction. Predict variables $x(s)$, where predictions sites lie on a regular grid of size 25x25 for the unit square. Visualize the Kriging surface and the prediction standard error. Compare with the true field. The expression for the kriging can be shown as below:
\begin{equation*}
\boldsymbol{\mu}_{\boldsymbol{x}|\boldsymbol{y}} &= \boldsymbol{\mu} + \boldsymbol{\Sigma F}^T(\boldsymbol{F\Sigma F}^T + \boldsymbol{T})^{-1}(\boldsymbol{y} - \boldsymbol{F\mu}) \\
\boldsymbol{\Sigma}_{\boldsymbol{x}|\boldsymbol{y}} &= \boldsymbol{\Sigma} - \boldsymbol{\Sigma F}^T (\boldsymbol{F\Sigma F}^T + \boldsymbol{T})^{-1}\boldsymbol{F\Sigma}
\end{equation*}
# parameter estimation loop
# (nomenclature as in lecture)
iter = 0
stats = list(c(iter, theta, alpha, l))
while(abs(l-l_old)>tol){
# current residual
Z = y - alpha*mu
# current covariance for the model
C = MaternCov(theta) + theta[3]**2*diag(N)
# current precision for the model
Q = solve(C)
# current gradient
dl_dtheta = dldtheta(theta, C, Q, Z)
# current Hessian
ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# update theta
theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# update alpha
alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# objective value (log-likelihood)
l_old = l
l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
# statistics
iter = iter + 1
stats[[iter]] = c(iter, theta, alpha, l)
}
# Q = solve(C)
# # current gradient
# dl_dtheta = dldtheta(theta, C, Q, Z)
# # current Hessian
# ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# # update theta
# theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# # update alpha
# alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# # objective value (log-likelihood)
# l_old = l
# l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
#
# # statistics
# iter = iter + 1
# stats[[iter]] = c(iter, theta, alpha, l)
while(abs(l-l_old)>tol){
# current residual
Z = y - alpha*mu
# current covariance for the model
C = MaternCov(theta) + theta[3]**2*diag(N)
# current precision for the model
# Q = solve(C)
# # current gradient
# dl_dtheta = dldtheta(theta, C, Q, Z)
# # current Hessian
# ddl_dthetadtheta = ddldthetadtheta(theta, C, Q)
# # update theta
# theta = theta - solve(ddl_dthetadtheta)%*%dl_dtheta
# # update alpha
# alpha = solve(t(mu)%*%Q%*%mu)%*%t(mu)%*%Q%*%y
# # objective value (log-likelihood)
# l_old = l
# l = -0.5*log(det(C)) - 0.5*t(Z)%*%solve(C)%*%Z
#
# # statistics
# iter = iter + 1
# stats[[iter]] = c(iter, theta, alpha, l)
}
print(MaternCov(theta))
print(dim(MaternCov(theta)))
H
dim(H)
# Cov = sigma**2*(1+phi*H)*exp(-phi*H)
Cov = sigma**2*(1+phi*t)*exp(-phi*t)
# Output:
# cov matrix in size of distance matrix H
MaternCov <- function(theta){
sigma=theta[1]
phi=theta[2]
tau=theta[3]
# Cov = sigma**2*(1+phi*H)*exp(-phi*H)
Cov = sigma**2*(1+phi*t)*exp(-phi*t)
return(Cov)
}
# Covariance matrix
Cov = MaternCov(theta)
# simulation
LCov = t (chol(Cov))
y0 = LCov %*% rnorm(N)
mu = ((s[,1]-0.5)+(s[,2]-0.5))
y = y0 + alpha*mu + rnorm(N, mean=0, sd=tau)
# simulation
LCov = t (chol(Cov))
y0 = LCov %*% rnorm(N)
y0 = LCov %*% rnorm(N)
mu = ((s[,1]-0.5)+(s[,2]-0.5))
dim(LCov)
rnorm(N)
dim(rnorm(N))
LCov %*% rnorm(N)
dim(L_temp)
N
set.seed(0421)
# sample locations
N = 200
s = matrix(runif(2*N), ncol=2)
plot(s[,1], s[,2], pch=4,
main="Observation sites", xlab="", ylab="")
# Distance matrix
# (without packages, since only one-time cost)
H = matrix(0, ncol=N, nrow=N)
for (i in 1:N){
for (j in 1:N){
H[i,j] = sqrt((s[i,1]-s[j,1])**2+(s[i,2]-s[j,2])**2)
}
}
# parameters
sigma = 1.0
phi = 10.0
tau = 0.05
theta = c(sigma, phi, tau)
alpha = 1.0
# Output:
C = F*Sigma*F.T + T
C_matrix <- function(theta){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
Sigma = Matern_cov(sigma, phi, t)
C = Fmatrix %*% Sigma %*% t(Fmatrix) + diag(M) * tau^2
return(C)
}
# Output:
# cov matrix in size of distance matrix H
MaternCov <- function(theta){
sigma=theta[1]
phi=theta[2]
tau=theta[3]
# Cov = sigma**2*(1+phi*H)*exp(-phi*H)
Cov = sigma**2*(1+phi*t)*exp(-phi*t)
return(Cov)
}
# Covariance matrix
Cov = MaternCov(theta)
# simulation
LCov = t (chol(Cov))
y0 = LCov %*% rnorm(N)
N
dim(Cov)

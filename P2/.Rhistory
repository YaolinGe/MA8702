V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
# No_iter = No_iter + 1
}
a = 2
a ^ 2
a ** 2
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
Beta[No_iter, ] = t(beta)
z = y_sampled - G %*% beta
lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
Likelihood[No_iter, ] = lik
# Find dC*/dtheta
# dC_dSgm = dC_dsigma(theta)
# dC_dPhi = dC_dphi(theta)
# dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
# No_iter = No_iter + 1
}
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
# beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# # beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
# Beta[No_iter, ] = t(beta)
# z = y_sampled - G %*% beta
# lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
# Likelihood[No_iter, ] = lik
# Find dC*/dtheta
# dC_dSgm = dC_dsigma(theta)
# dC_dPhi = dC_dphi(theta)
# dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
# print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
# No_iter = No_iter + 1
}
#%%
C_matrix <- function(theta){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
Sigma = Matern_cov(sigma, phi, t)
C = Fmatrix %*% Sigma %*% t(Fmatrix) + diag(M) * tau^2
return(C)
}
dC_dsigma <- function(theta){
# sigma = theta$sigma
# phi = theta$phi
# tau = theta$tau
sigma = theta[1]
phi = theta[2]
tau = theta[3]
Km = Matern_cov(1.0, phi, t) # t here is the distance matrix, H is the design matrix, similar to X
dC_dsgm = Fmatrix %*% Km %*% t(Fmatrix)
return(dC_dsgm)
}
dC_dphi <- function(theta){
# sigma = theta$sigma
# phi = theta$phi
# tau = theta$tau
sigma = theta[1]
phi = theta[2]
tau = theta[3]
Kn = sigma ^ 2 * (-phi * t) * exp(-phi * t)
return(Fmatrix %*% Kn %*% t(Fmatrix))
}
dC_dtau <- function(theta){
return(diag(M))
}
# Use fisher scoring to find MLE parameters
# beta = np.zeros([3, 1])
beta = matrix(c(-2.1, 3.1, .9), nrow = 3, ncol = 1)
theta = rbind(.245, 9.3, .003)
MAX_ITER = 5000
No_iter = 0
epsilon = 10
Beta = matrix(0, nrow = MAX_ITER, ncol = 3)
Likelihood = matrix(0, nrow = MAX_ITER, ncol = 1)
while (No_iter < MAX_ITER & epsilon > .0001){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
print(sigma)
print(phi)
print(tau)
C = C_matrix(theta)
# beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# # beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
# Beta[No_iter, ] = t(beta)
# z = y_sampled - G %*% beta
# lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
# Likelihood[No_iter, ] = lik
# Find dC*/dtheta
# dC_dSgm = dC_dsigma(theta)
# dC_dPhi = dC_dphi(theta)
# dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
# print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
MAX_ITER = 5
No_iter = 0
epsilon = 10
Beta = matrix(0, nrow = MAX_ITER, ncol = 3)
Likelihood = matrix(0, nrow = MAX_ITER, ncol = 1)
while (No_iter < MAX_ITER & epsilon > .0001){
sigma = theta[1]
phi = theta[2]
tau = theta[3]
print(sigma)
print(phi)
print(tau)
C = C_matrix(theta)
# beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# # beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
# Beta[No_iter, ] = t(beta)
# z = y_sampled - G %*% beta
# lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
# Likelihood[No_iter, ] = lik
# Find dC*/dtheta
# dC_dSgm = dC_dsigma(theta)
# dC_dPhi = dC_dphi(theta)
# dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
# print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
# beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# # beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
# Beta[No_iter, ] = t(beta)
# z = y_sampled - G %*% beta
# lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
# Likelihood[No_iter, ] = lik
# Find dC*/dtheta
# dC_dSgm = dC_dsigma(theta)
# dC_dPhi = dC_dphi(theta)
# dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
# print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
Beta[No_iter, ] = t(beta)
z = y_sampled - G %*% beta
lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
Likelihood[No_iter, ] = lik
# Find dC*/dtheta
# dC_dSgm = dC_dsigma(theta)
# dC_dPhi = dC_dphi(theta)
# dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
print(lik)
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
Beta[No_iter, ] = t(beta)
z = y_sampled - G %*% beta
lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
Likelihood[No_iter, ] = lik
# Find dC*/dtheta
dC_dSgm = dC_dsigma(theta)
dC_dPhi = dC_dphi(theta)
dC_dTau = dC_dtau(theta)
#
# u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
# u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
# u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
#
# u = rbind(u_sigma, u_eta, u_tau)
#
# V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
# V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
# V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
# V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
# V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
# V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
# V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
# V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
# V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
#
# V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
print(lik)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
Beta[No_iter, ] = t(beta)
z = y_sampled - G %*% beta
lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
Likelihood[No_iter, ] = lik
# Find dC*/dtheta
dC_dSgm = dC_dsigma(theta)
dC_dPhi = dC_dphi(theta)
dC_dTau = dC_dtau(theta)
u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
u = rbind(u_sigma, u_eta, u_tau)
V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
# print(lik)
print(No_iter)
# theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
# epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
# theta = theta_new
# print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
while (No_iter < MAX_ITER & epsilon > .0001){
C = C_matrix(theta)
beta = solve(t(G) %*% solve(C, G), t(G) %*% solve(C, y_sampled))
# beta = np.linalg.solve(np.dot(G.T, np.linalg.solve(C, G)), np.dot(G.T, np.linalg.solve(C, y_sampled)))
Beta[No_iter, ] = t(beta)
z = y_sampled - G %*% beta
lik = -M/2 * log(2 * pi) - 1/2 * log(det(C)) -  1/2 * t(z) %*% solve(C, z) # otherwise, it becomes inf
Likelihood[No_iter, ] = lik
# Find dC*/dtheta
dC_dSgm = dC_dsigma(theta)
dC_dPhi = dC_dphi(theta)
dC_dTau = dC_dtau(theta)
u_sigma = -1/2 * sum(diag(solve(C, dC_dSgm)) + 1/2 * t(z) %*% solve(C, dC_dSgm %*% solve(C, z)))
u_eta = -1 / 2 * sum(diag(solve(C, dC_dEta)) + 1 / 2 * t(z) %*% solve(C, dC_dEta %*% solve(C, z)))
u_tau = -1 / 2 * sum(diag(solve(C, dC_dTau)) + 1 / 2 * t(z) %*% solve(C, dC_dTau %*% solve(C, z)))
u = rbind(u_sigma, u_eta, u_tau)
V11 = -1/2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dSgm)))))
V12 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dPhi)))))
V13 = -1 / 2 * sum(diag(solve(C, (dC_dSgm %*% solve(C, dC_dTau)))))
V21 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dSgm)))))
V22 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dPhi)))))
V23 = -1 / 2 * sum(diag(solve(C, (dC_dPhi %*% solve(C, dC_dTau)))))
V31 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dSgm)))))
V32 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dPhi)))))
V33 = -1 / 2 * sum(diag(solve(C, (dC_dTau %*% solve(C, dC_dTau)))))
V = matrix(c(V11, V12, V13, V21, V22, V23, V31, V32, V33), nrow = 3, ncol = 3)
# print(lik)
# print(No_iter)
theta_new = theta - solve(V, u)  # here it is minus, but in the book, it says plus, needs to be rechecked
epsilon = norm(theta_new - theta, type = "2") / norm(beta, type = "2")
theta = theta_new
print(paste(epsilon , " , iter no is ", No_iter))
No_iter = No_iter + 1
}
plot(Likelihood, 'k')
Likelihood
plot(Likelihood[, 1], 'k')
plot(c(1:No_iter), Likelihood[], 'k')
plot(c(1:No_iter), Likelihood, 'k')
plot(c(1:No_iter), Likelihood)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
# print('Estimated sigma is ', sigmah, "\nEstimated eta is ", etah, \
#       "\nEstimated tau is ", tauh, "\nEstimated alpha is ", alphah)
print(cat("\nEstimated sigma is ", round(sigmah, digits = 3), "; True sigma is ", THETA_TRUE[0],
"\nEstimated eta is ", round(etah, digits = 2), "; True eta is ", THETA_TRUE[1],
"\nEstimated tau is ", round(tauh, digits = 5), "; True tau is ", THETA_TRUE[2],
"\nEstimated beta1 is ", round(beta1, digits = 2), "; True beta1 is ", BETA_TRUE[0],
"\nEstimated beta2 is ", round(beta2, digits = 2), "; True beta2 is ", BETA_TRUE[1],
"\nEstimated beta3 is ", round(beta3, digits = 2), "; True beta3 is ", BETA_TRUE[2]))
# print('Estimated sigma is ', sigmah, "\nEstimated eta is ", etah, \
#       "\nEstimated tau is ", tauh, "\nEstimated alpha is ", alphah)
print(cat("\nEstimated sigma is ", round(sigmah, digits = 3), "; True sigma is ", THETA_TRUE[1],
"\nEstimated eta is ", round(etah, digits = 2), "; True eta is ", THETA_TRUE[2],
"\nEstimated tau is ", round(tauh, digits = 5), "; True tau is ", THETA_TRUE[3],
"\nEstimated beta1 is ", round(beta1, digits = 2), "; True beta1 is ", BETA_TRUE[1],
"\nEstimated beta2 is ", round(beta2, digits = 2), "; True beta2 is ", BETA_TRUE[2],
"\nEstimated beta3 is ", round(beta3, digits = 2), "; True beta3 is ", BETA_TRUE[3]))
Sigmah = Matern_cov(sigmah, phih, t) # estimated covariance matrix
# alphah = (sum(np.abs(beta)) / 3).squeeze()
thetah = theta
sigmah = theta[1]
phih = theta[2]
tauh = theta[3]
betah = beta
beta1 = beta[1]
beta2 = beta[2]
beta3 = beta[3]
# print('Estimated sigma is ', sigmah, "\nEstimated eta is ", etah, \
#       "\nEstimated tau is ", tauh, "\nEstimated alpha is ", alphah)
print(cat("\nEstimated sigma is ", round(sigmah, digits = 3), "; True sigma is ", THETA_TRUE[1],
"\nEstimated phi is ", round(phih, digits = 2), "; True phi is ", THETA_TRUE[2],
"\nEstimated tau is ", round(tauh, digits = 5), "; True tau is ", THETA_TRUE[3],
"\nEstimated beta1 is ", round(beta1, digits = 2), "; True beta1 is ", BETA_TRUE[1],
"\nEstimated beta2 is ", round(beta2, digits = 2), "; True beta2 is ", BETA_TRUE[2],
"\nEstimated beta3 is ", round(beta3, digits = 2), "; True beta3 is ", BETA_TRUE[3]))
Sigmah = Matern_cov(sigmah, phih, t) # estimated covariance matrix
Lh = chol(Sigmah)
mh = H %*% betah + Lh %*% rnorm(n)
xp = mh + Sigmah %*% t(Fmatrix) %*% solve(C, (y_sampled - Fmatrix %*% mh))
plotf(xp, "posterior mean")
Sigmap = Sigmah - Sigmah %*% t(Fmatrix) %*% solve(Ch, Fmatrix %*% Sigmah)
Ch = C_matrix(thetah)
xp = mh + Sigmah %*% t(Fmatrix) %*% solve(C, (y_sampled - Fmatrix %*% mh))
plotf(xp, "posterior mean")
Sigmap = Sigmah - Sigmah %*% t(Fmatrix) %*% solve(Ch, Fmatrix %*% Sigmah)
plotf(estd, "posterior std")
# plotf(Sigmap, "posterior covariance")
estd = sqrt(diag(Sigmap))
plotf(estd, "posterior std")
MSE = sqrt(sum(abs(xp - mu_real) ** 2) / n)
print("The prediction error is ", MSE)
MSE = sqrt(sum(abs(xp - mu_real) ** 2) / n)
print("The prediction error is ", MSE)
print(cat("The prediction error is ", MSE))
print(cat("The prediction error is ", MSE))
MSE
print(paste("The prediction error is ", MSE))
a = rnorm(4, 4, )
a
a = rnorm(10, 4, 4)
a
suppressPackageStartupMessages(library(knitr))
knitr::opts_chunk$set(echo = FALSE, message=FALSE,warning = FALSE, error = FALSE)
# Plot the covariance matrix
levelplot(t(Sigma),
col.regions = coul, main = "Covariance matrix",
ylim=c(100,1))
source('~/.active-rstudio-document', echo=TRUE)
# sizes
n <- 100
# define regular grid of locations
sites1v <- array((1:n),c(n,1))
# Prior mean
m <- 0
# compute East and North distances on grid
ww <- array(1,c(n,1))
# determine the distance matrix
H <- abs(sites1v%*%t(ww)-ww %*% t(sites1v))
# Exponential covariance model
Sigma <- exp(-0.1*H)
# Plot the covariance matrix
levelplot(t(Sigma),
col.regions = coul, main = "Covariance matrix",
ylim=c(100,1))
# Plot the covariance matrix
levelplot(t(Sigma),
col.regions = coul, main = "Covariance matrix",
ylim=c(100,1))
